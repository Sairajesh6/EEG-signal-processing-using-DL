{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":59093,"databundleVersionId":7469972,"sourceType":"competition"},{"sourceId":7447509,"sourceType":"datasetVersion","datasetId":4334995}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import StratifiedKFold\nfrom torch.cuda.amp import GradScaler, autocast\nimport timm\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom tqdm import tqdm\nimport torchvision.transforms.v2 as v2\nimport torch.nn.functional as F\n\nclass EEGSpectrogramDataset(Dataset):\n    def __init__(self, eeg_ids, spectrogram_dict, label_dict):\n        self.eeg_ids = eeg_ids\n        self.spectrogram_dict = spectrogram_dict\n        self.label_dict = label_dict\n\n        self.transform = v2.Compose([\n            v2.Resize((224, 224)),\n            v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n        \n    def __len__(self):\n        return len(self.eeg_ids)\n    \n    def __getitem__(self, idx):\n        eeg_id = self.eeg_ids[idx]\n        spectrogram = self.spectrogram_dict[eeg_id]\n        \n        label_str = self.label_dict[eeg_id]\n        label = self._label_to_index(label_str)\n\n        stacked = np.vstack([spectrogram[..., i] for i in range(4)])[..., np.newaxis]\n        stacked = torch.tensor(stacked, dtype=torch.float32).permute(2, 0, 1)\n    \n        rgb = torch.cat([stacked, stacked, stacked], dim=0)\n        \n        # Resize to 224x224 using bilinear interpolation\n        rgb = F.interpolate(rgb.unsqueeze(0), \n                          size=(224, 224), \n                          mode='bilinear',\n                          align_corners=False).squeeze(0)\n        \n        # Apply transforms\n        rgb = self.transform(rgb)\n        \n        label = torch.tensor(label, dtype=torch.long)\n        \n        return rgb, label\n    \n    def _label_to_index(self, label_str):\n        label_mapping = {\n            'Seizure': 0,\n            'LPD': 1,\n            'GPD': 2,\n            'LRDA': 3,\n            'GRDA': 4,\n            'Other': 5\n        }\n        return label_mapping.get(label_str, 5)\n\n# Load data\nspectrogram_dict = np.load('/kaggle/input/brain-eeg-spectrograms/eeg_specs.npy', allow_pickle=True).item()\ntrain_df = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/train.csv')\nlabel_dict = dict(zip(train_df['eeg_id'], train_df['expert_consensus']))\n\ncommon_eeg_ids = [eeg_id for eeg_id in spectrogram_dict.keys() if eeg_id in label_dict]\n\nprint(f\"Total EEG IDs in spectrogram dict: {len(spectrogram_dict)}\")\nprint(f\"Total EEG IDs in labels: {len(label_dict)}\")\nprint(f\"Common EEG IDs with both: {len(common_eeg_ids)}\")\nprint(f\"Sample spectrogram shape: {spectrogram_dict[common_eeg_ids[0]].shape}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-11T16:21:09.084742Z","iopub.execute_input":"2025-04-11T16:21:09.085003Z","iopub.status.idle":"2025-04-11T16:22:19.148916Z","shell.execute_reply.started":"2025-04-11T16:21:09.084981Z","shell.execute_reply":"2025-04-11T16:22:19.148261Z"}},"outputs":[{"name":"stdout","text":"Total EEG IDs in spectrogram dict: 17089\nTotal EEG IDs in labels: 17089\nCommon EEG IDs with both: 17089\nSample spectrogram shape: (128, 256, 4)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"class EarlyStopping:\n    def __init__(self, patience=3, verbose=False):\n        self.patience = patience\n        self.counter = 0\n        self.best_loss = float('inf')\n        self.early_stop = False\n        self.verbose = verbose\n\n    def __call__(self, val_loss):\n        if val_loss < self.best_loss:\n            self.best_loss = val_loss\n            self.counter = 0\n        else:\n            self.counter += 1\n            if self.verbose:\n                print(f\"EarlyStopping: {self.counter}/{self.patience} without improvement.\")\n            if self.counter >= self.patience:\n                self.early_stop = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T16:23:09.004356Z","iopub.execute_input":"2025-04-11T16:23:09.004880Z","iopub.status.idle":"2025-04-11T16:23:09.009871Z","shell.execute_reply.started":"2025-04-11T16:23:09.004860Z","shell.execute_reply":"2025-04-11T16:23:09.009161Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from torch.cuda.amp import autocast, GradScaler","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T16:25:51.105593Z","iopub.execute_input":"2025-04-11T16:25:51.106276Z","iopub.status.idle":"2025-04-11T16:25:51.109913Z","shell.execute_reply.started":"2025-04-11T16:25:51.106250Z","shell.execute_reply":"2025-04-11T16:25:51.109163Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"os.makedirs(\"/kaggle/working/saved_models\", exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T16:32:38.569084Z","iopub.execute_input":"2025-04-11T16:32:38.569414Z","iopub.status.idle":"2025-04-11T16:32:38.574239Z","shell.execute_reply.started":"2025-04-11T16:32:38.569388Z","shell.execute_reply":"2025-04-11T16:32:38.573463Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Prepare for K-Fold\nnum_folds = 5\nbatch_size = 16\nnum_epochs = 20\nnum_classes = 6\nfp16 = True\n\n# Get labels for stratification\nlabels = [label_dict[eeg_id] for eeg_id in common_eeg_ids]\nskf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n\n# Store fold results\nfold_results = []\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(common_eeg_ids, labels)):\n    print(f\"\\n{'='*40}\")\n    print(f\"Fold {fold + 1}/{num_folds}\")\n    print(f\"{'='*40}\")\n    \n    # Create datasets\n    train_eeg_ids = [common_eeg_ids[i] for i in train_idx]\n    val_eeg_ids = [common_eeg_ids[i] for i in val_idx]\n    \n    train_dataset = EEGSpectrogramDataset(train_eeg_ids, spectrogram_dict, label_dict)\n    val_dataset = EEGSpectrogramDataset(val_eeg_ids, spectrogram_dict, label_dict)\n    \n    # Create dataloaders\n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=batch_size,\n        shuffle=True,\n        num_workers=4,\n        pin_memory=True,\n        drop_last=True\n    )\n    \n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=batch_size,\n        shuffle=False,\n        num_workers=4,\n        pin_memory=True\n    )\n    \n    # Initialize model\n    model = timm.create_model(\"swin_tiny_patch4_window7_224\", pretrained=True, num_classes=num_classes)\n    \n    # Multi-GPU support\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    if torch.cuda.device_count() > 1:\n        print(f\"Using {torch.cuda.device_count()} GPUs!\")\n        model = nn.DataParallel(model)\n    model = model.to(device)\n    \n    # Training setup\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.AdamW(model.parameters(), lr=2e-4, weight_decay=0.01)\n    scheduler = CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-7)\n    scaler = GradScaler(enabled=fp16)\n    early_stopper = EarlyStopping(patience=3, verbose=True)\n    \n    best_val_acc = 0.0\n    best_val_loss = float('inf')\n    \n    for epoch in range(num_epochs):\n        model.train()\n        running_loss, correct, total = 0.0, 0, 0\n\n        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n            images, labels = images.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            with autocast(enabled=fp16):\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n\n            running_loss += loss.item()\n            _, preds = torch.max(outputs, 1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n\n        scheduler.step()\n        \n        train_acc = correct / total\n        avg_train_loss = running_loss / len(train_loader)\n        print(f\"\\nEpoch [{epoch+1}/{num_epochs}]\")\n        print(f\"Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n\n        # Validation\n        model.eval()\n        val_loss, val_correct, val_total = 0.0, 0, 0\n\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                with autocast(enabled=fp16):\n                    outputs = model(images)\n                    loss = criterion(outputs, labels)\n\n                val_loss += loss.item()\n                _, preds = torch.max(outputs, 1)\n                val_correct += (preds == labels).sum().item()\n                val_total += labels.size(0)\n\n        val_acc = val_correct / val_total\n        avg_val_loss = val_loss / len(val_loader)\n        print(f\"Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_acc:.4f}\")\n\n        # Save best model for this fold\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            best_val_loss = avg_val_loss\n            torch.save(model.state_dict(), f\"/kaggle/working/saved_models/swin_fold{fold+1}_best.pth\")\n            print(f\"Best model for fold {fold+1} saved with val accuracy: {val_acc:.4f}\")\n\n        early_stopper(avg_val_loss)\n        if early_stopper.early_stop:\n            print(\"Early stopping triggered. Ending training for this fold.\")\n            break\n    \n    # Store fold results\n    fold_results.append({\n        'fold': fold + 1,\n        'best_val_acc': best_val_acc,\n        'best_val_loss': best_val_loss\n    })\n\n# Print final results\nprint(\"\\nFinal Results:\")\nfor result in fold_results:\n    print(f\"Fold {result['fold']}: Val Acc: {result['best_val_acc']:.4f}, Val Loss: {result['best_val_loss']:.4f}\")\n\nmean_acc = np.mean([r['best_val_acc'] for r in fold_results])\nmean_loss = np.mean([r['best_val_loss'] for r in fold_results])\nprint(f\"\\nMean Val Accuracy: {mean_acc:.4f}\")\nprint(f\"Mean Val Loss: {mean_loss:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T16:32:47.634161Z","iopub.execute_input":"2025-04-11T16:32:47.634432Z","execution_failed":"2025-04-11T17:17:20.306Z"}},"outputs":[{"name":"stdout","text":"\n========================================\nFold 1/5\n========================================\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/1374984915.py:59: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler(enabled=fp16)\nEpoch 1/20:   0%|          | 0/854 [00:00<?, ?it/s]/tmp/ipykernel_31/1374984915.py:73: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=fp16):\nEpoch 1/20: 100%|██████████| 854/854 [02:02<00:00,  6.98it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch [1/20]\nTrain Loss: 1.4986, Train Accuracy: 0.4483\n","output_type":"stream"},{"name":"stderr","text":"\n/tmp/ipykernel_31/1374984915.py:100: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=fp16):\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 1.4353, Val Accuracy: 0.4912\nBest model for fold 1 saved with val accuracy: 0.4912\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/20: 100%|██████████| 854/854 [02:02<00:00,  6.98it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch [2/20]\nTrain Loss: 1.3696, Train Accuracy: 0.4930\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 1.2356, Val Accuracy: 0.5477\nBest model for fold 1 saved with val accuracy: 0.5477\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/20: 100%|██████████| 854/854 [02:02<00:00,  6.96it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch [3/20]\nTrain Loss: 1.2379, Train Accuracy: 0.5492\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 1.1905, Val Accuracy: 0.5690\nBest model for fold 1 saved with val accuracy: 0.5690\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/20: 100%|██████████| 854/854 [02:02<00:00,  6.96it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch [4/20]\nTrain Loss: 1.0758, Train Accuracy: 0.6114\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 1.1849, Val Accuracy: 0.5591\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/20: 100%|██████████| 854/854 [02:02<00:00,  6.97it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch [5/20]\nTrain Loss: 0.9677, Train Accuracy: 0.6511\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 1.0124, Val Accuracy: 0.6202\nBest model for fold 1 saved with val accuracy: 0.6202\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/20: 100%|██████████| 854/854 [02:02<00:00,  6.97it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch [6/20]\nTrain Loss: 0.8888, Train Accuracy: 0.6789\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 0.8761, Val Accuracy: 0.6823\nBest model for fold 1 saved with val accuracy: 0.6823\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/20: 100%|██████████| 854/854 [02:02<00:00,  6.97it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch [7/20]\nTrain Loss: 0.8044, Train Accuracy: 0.7089\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 0.8342, Val Accuracy: 0.6984\nBest model for fold 1 saved with val accuracy: 0.6984\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/20: 100%|██████████| 854/854 [02:02<00:00,  6.97it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch [8/20]\nTrain Loss: 0.7323, Train Accuracy: 0.7364\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 0.7937, Val Accuracy: 0.7203\nBest model for fold 1 saved with val accuracy: 0.7203\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/20: 100%|██████████| 854/854 [02:02<00:00,  6.97it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch [9/20]\nTrain Loss: 0.6686, Train Accuracy: 0.7600\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 0.7925, Val Accuracy: 0.7133\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/20: 100%|██████████| 854/854 [02:02<00:00,  6.96it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch [10/20]\nTrain Loss: 0.6238, Train Accuracy: 0.7783\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 0.7971, Val Accuracy: 0.7139\nEarlyStopping: 1/3 without improvement.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/20: 100%|██████████| 854/854 [02:02<00:00,  6.97it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch [11/20]\nTrain Loss: 0.6019, Train Accuracy: 0.7878\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 0.7964, Val Accuracy: 0.7156\nEarlyStopping: 2/3 without improvement.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/20: 100%|██████████| 854/854 [02:02<00:00,  6.97it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch [12/20]\nTrain Loss: 0.6078, Train Accuracy: 0.7829\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 0.8022, Val Accuracy: 0.7142\nEarlyStopping: 3/3 without improvement.\nEarly stopping triggered. Ending training for this fold.\n\n========================================\nFold 2/5\n========================================\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/20: 100%|██████████| 854/854 [02:02<00:00,  6.97it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch [1/20]\nTrain Loss: 1.3540, Train Accuracy: 0.5112\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 1.1184, Val Accuracy: 0.5848\nBest model for fold 2 saved with val accuracy: 0.5848\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/20: 100%|██████████| 854/854 [02:02<00:00,  6.96it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch [2/20]\nTrain Loss: 1.0813, Train Accuracy: 0.6104\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 1.0201, Val Accuracy: 0.6325\nBest model for fold 2 saved with val accuracy: 0.6325\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/20: 100%|██████████| 854/854 [02:02<00:00,  6.96it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch [3/20]\nTrain Loss: 0.9357, Train Accuracy: 0.6647\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 0.9080, Val Accuracy: 0.6697\nBest model for fold 2 saved with val accuracy: 0.6697\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/20: 100%|██████████| 854/854 [02:02<00:00,  6.96it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch [4/20]\nTrain Loss: 0.8510, Train Accuracy: 0.6937\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 0.8178, Val Accuracy: 0.7159\nBest model for fold 2 saved with val accuracy: 0.7159\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/20: 100%|██████████| 854/854 [02:02<00:00,  6.97it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch [5/20]\nTrain Loss: 0.7744, Train Accuracy: 0.7242\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 0.8108, Val Accuracy: 0.7209\nBest model for fold 2 saved with val accuracy: 0.7209\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/20: 100%|██████████| 854/854 [02:02<00:00,  6.97it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch [6/20]\nTrain Loss: 0.6782, Train Accuracy: 0.7591\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 0.8723, Val Accuracy: 0.7057\nEarlyStopping: 1/3 without improvement.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/20: 100%|██████████| 854/854 [02:02<00:00,  6.96it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch [7/20]\nTrain Loss: 0.5648, Train Accuracy: 0.8023\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 0.8352, Val Accuracy: 0.7305\nBest model for fold 2 saved with val accuracy: 0.7305\nEarlyStopping: 2/3 without improvement.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/20: 100%|██████████| 854/854 [02:02<00:00,  6.97it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch [8/20]\nTrain Loss: 0.4377, Train Accuracy: 0.8473\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 0.8756, Val Accuracy: 0.7326\nBest model for fold 2 saved with val accuracy: 0.7326\nEarlyStopping: 3/3 without improvement.\nEarly stopping triggered. Ending training for this fold.\n\n========================================\nFold 3/5\n========================================\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/20:   5%|▍         | 42/854 [00:06<01:55,  7.01it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}